{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "error log\n",
    "ValueError: Error when checking target: expected conv2d_22 to have shape (61, 61, 3) but got array with shape (64, 64, 3)\n",
    "output of layer is the first and the target is 64*64*3, need to match output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" for CPU\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11001903313406261294\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2021813478412533670\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/FA2018/tutorials/ferienakademie2018-accelerating-physics-with-deep-learning/')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces CPU usage\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#GPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pkicsiny\\\\Desktop\\\\FA2018\\\\tutorials\\\\ferienakademie2018-accelerating-physics-with-deep-learning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sm_goe503_1050_57.npz',\n",
       " 'sm_goe503_1079_209.npz',\n",
       " 'sm_goe503_1093_355.npz',\n",
       " 'sm_goe503_1110_304.npz',\n",
       " 'sm_goe503_1152_78.npz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = os.getcwd() + '/data/trainSmallFA'\n",
    "files = listdir(dataDir)\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLength = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of inputs and outputs (predictions of the network)\n",
    "inputs = np.empty((totalLength,3,64,64))\n",
    "targets = np.empty_like(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs) == np.shape(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input-target array: (751, 3, 64, 64)\n",
      "Shape of an element of input + output: (6, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "for i, file in enumerate(files):\n",
    "    npfile = np.load(dataDir +'/' + file)\n",
    "    #a file contains 6 images: 3 for input p, vx, vy and output (ground truth) \n",
    "    d = npfile['a']\n",
    "    inputs[i]  = d[0:3]   # inx, iny, mask \n",
    "    targets[i] = d[3:6]   # p, velx, vely\n",
    "    if c:\n",
    "        print('Shape of input-target array:',np.shape(targets))\n",
    "        print('Shape of an element of input + output:',np.shape(d))\n",
    "        # splits input file content of 6 channels to 3-3\n",
    "        c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input maxes: 98.70918772289284 36.22861719358889 1.0\n",
      "Input mins: 0.0 0.0 0.0\n",
      "Target maxes: 4321.8 171.772 140.251\n",
      "Target mins: -13757.3 -71.886 -58.4272\n"
     ]
    }
   ],
   "source": [
    "print('Input maxes:',inputs[:,0,:,:].max(), inputs[:,1,:,:].max(), inputs[:,2,:,:].max())\n",
    "print('Input mins:',inputs[:,0,:,:].min(), inputs[:,1,:,:].min(), inputs[:,2,:,:].min())\n",
    "print('Target maxes:',targets[:,0,:,:].max(), targets[:,1,:,:].max(), targets[:,2,:,:].max())\n",
    "print('Target mins:',targets[:,0,:,:].min(), targets[:,1,:,:].min(), targets[:,2,:,:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_inputs, normalized_targets, vxmax, vymax = normalize_data(inputs,targets,norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized input maxes: 98.70918772289284 36.22861719358889 1.0\n",
      "Normalized input mins: 0.0 0.0 0.0\n",
      "Normalized target maxes: 0.5181714179504846 1.739651600742902 1.7284380207634795\n",
      "Normalized target mins: -1.957152811908768 -0.729521000704373 -0.7706419276952202\n"
     ]
    }
   ],
   "source": [
    "print('Normalized input maxes:',normalized_inputs[:,0,:,:].max(), normalized_inputs[:,1,:,:].max(), normalized_inputs[:,2,:,:].max())\n",
    "print('Normalized input mins:',normalized_inputs[:,0,:,:].min(), normalized_inputs[:,1,:,:].min(), normalized_inputs[:,2,:,:].min())\n",
    "print('Normalized target maxes:',normalized_targets[:,0,:,:].max(), normalized_targets[:,1,:,:].max(), normalized_targets[:,2,:,:].max())\n",
    "print('Normalized target mins:',normalized_targets[:,0,:,:].min(), normalized_targets[:,1,:,:].min(), normalized_targets[:,2,:,:].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test dataset\n",
    "testDir = os.getcwd() + '/data/testDataSetFinal'\n",
    "testFiles = listdir(testDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = []\n",
    "test_targets = []\n",
    "for i, file in enumerate(testFiles):\n",
    "    npfile = np.load(testDir +'/' + file)\n",
    "    #a file contains 6 images: 3 for input p, vx, vy and output (ground truth) \n",
    "    d = npfile['a']\n",
    "    test_inputs.append(d[0:3])   # inx, iny, mask \n",
    "    test_targets.append(d[3:6])   # p, velx, vely\n",
    "test_inputs = np.asarray(test_inputs)\n",
    "test_targets = np.asarray(test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_inputs, n_test_targets, n_vxmax, n_vymax = normalize_data(test_inputs,test_targets,norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1d60e02bb38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d60e18e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_inputs[0,2,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_inputs = normalized_inputs\n",
    "train_val_targets = normalized_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_val_inputs,train_val_targets,test_inputs,test_targets = randsplit(normalized_inputs,normalized_targets,frac=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (751, 64, 64, 3) (751, 64, 64, 3)\n",
      "Test data shape: (10, 64, 64, 3) (10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "train_val_inputs  = train_val_inputs.transpose(0,2,3,1)\n",
    "train_val_targets = train_val_targets.transpose(0,2,3,1)\n",
    "\n",
    "#test dataset\n",
    "n_test_inputs  = n_test_inputs.transpose(0,2,3,1)\n",
    "n_test_targets = n_test_targets.transpose(0,2,3,1)\n",
    "\n",
    "print('Training data shape:',np.shape(train_val_inputs),np.shape(train_val_targets))\n",
    "print('Test data shape:',np.shape(n_test_inputs),np.shape(n_test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening if last layer is fcl\n",
    "#train_val_targets = np.reshape(train_val_targets,(len(train_val_targets),-1))\n",
    "#n_test_targets = np.reshape(n_test_targets,(len(n_test_targets),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (751, 64, 64, 3) (751, 64, 64, 3)\n",
      "Test data shape: (10, 64, 64, 3) (10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape:',np.shape(train_val_inputs),np.shape(train_val_targets))\n",
    "print('Test data shape:',np.shape(n_test_inputs),np.shape(n_test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution filters\n",
    "f1 = 8\n",
    "f2 = 3\n",
    "#kernel size\n",
    "k1 = 4\n",
    "k2 = 2\n",
    "#stride\n",
    "s1 = 4\n",
    "s2 = 2\n",
    "#padding\n",
    "p1 = 0\n",
    "p2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "\n",
    "conv1 = keras.layers.Conv2D(input_shape = (64,64,3),\n",
    "                              filters = f1,\n",
    "                              kernel_size=(k1,k1),\n",
    "                              strides=(s1, s1),\n",
    "                              padding='valid',\n",
    "                              data_format = \"channels_last\",\n",
    "                             activation = 'tanh')\n",
    "conv2 = keras.layers.Conv2D(input_shape = (16,16,3),\n",
    "                              filters = f2,\n",
    "                              kernel_size=(k2,k2),\n",
    "                              strides=(s2, s2),\n",
    "                              padding='same',\n",
    "                              data_format = \"channels_last\",\n",
    "                              activation = 'tanh')\n",
    "conv3 = keras.layers.Conv2D(input_shape = (8,8,3),\n",
    "                              filters = 3,\n",
    "                              kernel_size=(8,8),\n",
    "                              strides=(1, 1),\n",
    "                              padding='same',\n",
    "                              data_format = \"channels_last\",\n",
    "                              activation = 'tanh')\n",
    "upsample1 = keras.layers.UpSampling2D(size=(4, 4), data_format=\"channels_last\",input_shape = (8,8,3))\n",
    "dense1 = keras.layers.Dense(64*64*3,activation='tanh')\n",
    "#architeccture\n",
    "model.add(conv1)\n",
    "model.add(conv2)\n",
    "model.add(conv3)\n",
    "model.add(upsample1)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(dense1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2=keras.Sequential()\n",
    "\n",
    "init = keras.layers.Input(shape=(64,64,3))\n",
    "ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "Lr1 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown1)\n",
    "#64\n",
    "ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "Lr2 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown2)\n",
    "#32\n",
    "ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "Lr3 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown3)\n",
    "#16\n",
    "ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "Lr4 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown4)\n",
    "#8\n",
    "ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "Lr5 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown5)\n",
    "#4\n",
    "\n",
    "UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "#8\n",
    "merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "Lr6 = keras.layers.LeakyReLU(alpha=0.0)(Conv1)\n",
    "#8\n",
    "UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "#16\n",
    "merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "Lr7  = keras.layers.LeakyReLU(alpha=0.0)(Conv2)\n",
    "#16\n",
    "UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "#32\n",
    "Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "Lr8  = keras.layers.LeakyReLU(alpha=0.0)(Conv3)\n",
    "\n",
    "UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "#64\n",
    "Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'relu')(UpSamp4)\n",
    "\n",
    "Conv5   = keras.layers.Conv2D(filters=3,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'elu')(Conv4)\n",
    "\n",
    "model2 = keras.models.Model(inputs=init, outputs=Conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.tools.api.generator.api.keras.layers' has no attribute 'subtract'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-b048bda493ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrelative_error_tensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m model2.fit(train_val_inputs,\n\u001b[0;32m      4\u001b[0m           \u001b[0mtrain_val_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m         \u001b[0mhandle_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[1;34m(metrics, weights)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m               metric_result = weighted_metric_fn(\n\u001b[1;32m--> 503\u001b[1;33m                   y_true, y_pred, weights=weights, mask=masks[i])\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_metric_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \"\"\"\n\u001b[0;32m    437\u001b[0m     \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m     \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m       \u001b[1;31m# Cast the mask to floatX to avoid float64 upcasting in theano\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/pkicsiny/Desktop/FA2018/tutorials/ferienakademie2018-accelerating-physics-with-deep-learning\\functions.py\u001b[0m in \u001b[0;36mrelative_error_tensor\u001b[1;34m(truth, predictions)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \"\"\"\n\u001b[1;32m--> 143\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.tools.api.generator.api.keras.layers' has no attribute 'subtract'"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model2.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0005),loss='mean_squared_error', metrics=['accuracy',relative_error_tensor]) \n",
    "model2.fit(train_val_inputs,\n",
    "          train_val_targets,\n",
    "          batch_size = 50,\n",
    "          epochs=10,\n",
    "          validation_split = 0.1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss and network info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trainingcurves(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = model.predict(n_test_inputs, batch_size=1)\n",
    "truth     = n_test_targets\n",
    "\n",
    "predictions = np.reshape(predictions, (len(n_test_inputs),64,64,3))\n",
    "truth       = np.reshape(truth, (len(n_test_targets),64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_distribution(truth,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = arg_getter(truth,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(predictionset, ground_truth, index=-1):\n",
    "    \"\"\"\n",
    "    Plots various statistics on the training result..\n",
    "    :param predictionset: predictions\n",
    "    :param ground_truth: ground truth\n",
    "    :param index: index 0 is best result, ordered descending\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    length = len(predictionset)\n",
    "    if index > -1:\n",
    "        sampleindex = index\n",
    "    else:\n",
    "        sampleindex = np.random.random_integers(0, length - 1)\n",
    "\n",
    "    plt.figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "    print(sampleindex)\n",
    "    # predicted data\n",
    "    plt.subplot(331)\n",
    "    plt.title('Predicted pressure', fontsize=10)\n",
    "    plt.imshow(predictionset[sampleindex, :, :, 0], cmap='jet',\n",
    "               vmin=ground_truth[sampleindex, :, :, 0].min(),\n",
    "               vmax=ground_truth[sampleindex, :, :, 0].max())\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(332)\n",
    "    plt.title('Predicted x velocity', fontsize=10)\n",
    "    plt.imshow(predictionset[sampleindex, :, :, 1], cmap='jet',\n",
    "               vmin=ground_truth[sampleindex, :, :, 1].min(),\n",
    "               vmax=ground_truth[sampleindex, :, :, 1].max())\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(333)\n",
    "    plt.title('Predicted y velocity', fontsize=10)\n",
    "    plt.imshow(predictionset[sampleindex, :, :, 2], cmap='jet',\n",
    "               vmin=ground_truth[sampleindex, :, :, 2].min(),\n",
    "               vmax=ground_truth[sampleindex, :, :, 2].max())\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    # ground truth data\n",
    "    plt.subplot(334)\n",
    "    plt.title('Ground truth pressure', fontsize=10)\n",
    "    plt.imshow(ground_truth[sampleindex, :, :, 0], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(335)\n",
    "    plt.title('Ground truth x velocity', fontsize=10)\n",
    "    plt.imshow(ground_truth[sampleindex, :, :, 1], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(336)\n",
    "    plt.title('Ground truth y velocity', fontsize=10)\n",
    "    plt.imshow(ground_truth[sampleindex, :, :, 2], cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    # difference\n",
    "    plt.subplot(337)\n",
    "    p = ground_truth[sampleindex, :, :, 0] - predictionset[sampleindex, :, :, 0]\n",
    "    pmask = np.ma.masked_where(np.abs(p) <= 5e-3, p)\n",
    "    plt.title('Difference pressure', fontsize=10)\n",
    "    plt.imshow(pmask, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(338)\n",
    "    vx = ground_truth[sampleindex, :, :, 1] - predictionset[sampleindex, :, :, 1]\n",
    "    vxmask = np.ma.masked_where(np.abs(vx) <= 5e-3, vx)\n",
    "    plt.title('Difference x velocity', fontsize=10)\n",
    "    plt.imshow(vxmask, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(339)\n",
    "    vy = ground_truth[sampleindex, :, :, 2] - predictionset[sampleindex, :, :, 2]\n",
    "    vymask = np.ma.masked_where(np.abs(vy) <= 5e-3, vy)\n",
    "    plt.title('Difference y velocity', fontsize=10)\n",
    "    plt.imshow(vymask, cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.savefig('toy1.png')\n",
    "    plt.show()\n",
    "\n",
    "    # relative error\n",
    "    plt.figure(num=None, figsize=(20, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "    eps = 1e-8\n",
    "    plt.subplot(331)\n",
    "    plt.title('Rel. error pressure', fontsize=10)\n",
    "    relerrp = np.abs(ground_truth[sampleindex, :, :, 0]-predictionset[sampleindex, :, :, 0]) /np.abs(ground_truth[sampleindex,:, :, 0] + eps)\n",
    "    relerrmaskp = np.ma.masked_where(relerrp > 1e2, relerrp)\n",
    "    plt.imshow(relerrmaskp,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(332)\n",
    "    plt.title('Rel. error x velocity', fontsize=10)\n",
    "    relerrvx = np.abs(ground_truth[sampleindex, :, :, 1]-predictionset[sampleindex, :, :, 1]) /np.abs(ground_truth[sampleindex,:, :,1] + eps)\n",
    "    relerrmaskvx = np.ma.masked_where(relerrvx > 1e2, relerrvx)\n",
    "    plt.imshow(relerrmaskvx,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(333)\n",
    "    plt.title('Rel. error y velocity', fontsize=10)\n",
    "    relerrvy = np.abs(ground_truth[sampleindex, :, :, 2] - predictionset[sampleindex, :, :, 2]) /np.abs(ground_truth[sampleindex,:, :, 2] + eps)\n",
    "    relerrmaskvy = np.ma.masked_where(relerrvy > 1e2, relerrvy)\n",
    "    plt.imshow(relerrmaskvy,cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    plt.savefig('toy2.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter(predictions,truth,index = args[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_img(reference,output):\n",
    "    mean_ref = reference.sum(axis = 0)/len(reference)\n",
    "    mean_output = output.sum(axis = 0)/len(output)\n",
    "    rel_err = []\n",
    "    [rel_err.append(relative_error(mean_ref[:,:,ch], mean_output[:,:,ch])) for ch in range(0,3)]\n",
    "    ref_mean_truth = np.mean(np.abs(mean_ref))\n",
    "    ref_mean_pred = np.mean(np.abs(mean_output))\n",
    "    return mean_ref, mean_output, rel_err, ref_mean_truth, ref_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = denormalize_data(predictions, truth, n_vxmax,n_vymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ref, mean_output, rel_err, ref_mean_truth, ref_mean_pred = get_mean_img(truth,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mean_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(target[0,:,:,2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
