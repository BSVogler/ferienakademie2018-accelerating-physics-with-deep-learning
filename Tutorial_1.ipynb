{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "error log\n",
    "ValueError: Error when checking target: expected conv2d_22 to have shape (61, 61, 3) but got array with shape (64, 64, 3)\n",
    "output of layer is the first and the target is 64*64*3, need to match output\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#forces CPU usage\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #\"\" for CPU\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11661229012520867500\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1508248780\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5971688792552521280\n",
      "physical_device_desc: \"device: 0, name: GeForce GT 740M, pci bus id: 0000:01:00.0, compute capability: 3.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/pkicsiny/Desktop/FA2018/tutorials/ferienakademie2018-accelerating-physics-with-deep-learning/')\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forces CPU usage\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#GPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pkicsiny\\\\Desktop\\\\FA2018\\\\tutorials\\\\ferienakademie2018-accelerating-physics-with-deep-learning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sm_goe503_1050_57.npz',\n",
       " 'sm_goe503_1079_209.npz',\n",
       " 'sm_goe503_1093_355.npz',\n",
       " 'sm_goe503_1110_304.npz',\n",
       " 'sm_goe503_1152_78.npz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDir = os.getcwd() + '/data/trainSmallFA'\n",
    "files = listdir(dataDir)\n",
    "files[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLength = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array of inputs and outputs (predictions of the network)\n",
    "inputs = np.empty((totalLength,3,64,64))\n",
    "targets = np.empty_like(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(inputs) == np.shape(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prerpocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 1\n",
    "for i, file in enumerate(files):\n",
    "    npfile = np.load(dataDir +'/' + file)\n",
    "    #a file contains 6 images: 3 for input p, vx, vy and output (ground truth) \n",
    "    d = npfile['a']\n",
    "    inputs[i]  = d[0:3]   # inx, iny, mask \n",
    "    targets[i] = d[3:6]   # p, velx, vely\n",
    "    if c:\n",
    "        print('Shape of input-target array:',np.shape(targets))\n",
    "        print('Shape of an element of input + output:',np.shape(d))\n",
    "        # splits input file content of 6 channels to 3-3\n",
    "        c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input maxes:',inputs[:,0,:,:].max(), inputs[:,1,:,:].max(), inputs[:,2,:,:].max())\n",
    "print('Input mins:',inputs[:,0,:,:].min(), inputs[:,1,:,:].min(), inputs[:,2,:,:].min())\n",
    "print('Target maxes:',targets[:,0,:,:].max(), targets[:,1,:,:].max(), targets[:,2,:,:].max())\n",
    "print('Target mins:',targets[:,0,:,:].min(), targets[:,1,:,:].min(), targets[:,2,:,:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_inputs, normalized_targets, vxmax, vymax = normalize_data(inputs,targets,norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normalized input maxes:',normalized_inputs[:,0,:,:].max(), normalized_inputs[:,1,:,:].max(), normalized_inputs[:,2,:,:].max())\n",
    "print('Normalized input mins:',normalized_inputs[:,0,:,:].min(), normalized_inputs[:,1,:,:].min(), normalized_inputs[:,2,:,:].min())\n",
    "print('Normalized target maxes:',normalized_targets[:,0,:,:].max(), normalized_targets[:,1,:,:].max(), normalized_targets[:,2,:,:].max())\n",
    "print('Normalized target mins:',normalized_targets[:,0,:,:].min(), normalized_targets[:,1,:,:].min(), normalized_targets[:,2,:,:].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test dataset\n",
    "testDir = os.getcwd() + '/data/testDataSetFinal'\n",
    "testFiles = listdir(testDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = []\n",
    "test_targets = []\n",
    "for i, file in enumerate(testFiles):\n",
    "    npfile = np.load(testDir +'/' + file)\n",
    "    #a file contains 6 images: 3 for input p, vx, vy and output (ground truth) \n",
    "    d = npfile['a']\n",
    "    test_inputs.append(d[0:3])   # inx, iny, mask \n",
    "    test_targets.append(d[3:6])   # p, velx, vely\n",
    "test_inputs = np.asarray(test_inputs)\n",
    "test_targets = np.asarray(test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_inputs, n_test_targets, n_vxmax, n_vymax = normalize_data(test_inputs,test_targets,norm = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_inputs = normalized_inputs\n",
    "train_val_targets = normalized_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_val_inputs,train_val_targets,test_inputs,test_targets = randsplit(normalized_inputs,normalized_targets,frac=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train_val_inputs  = train_val_inputs.transpose(0,2,3,1)\n",
    "train_val_targets = train_val_targets.transpose(0,2,3,1)\n",
    "\n",
    "#test dataset\n",
    "n_test_inputs  = n_test_inputs.transpose(0,2,3,1)\n",
    "n_test_targets = n_test_targets.transpose(0,2,3,1)\n",
    "\n",
    "print('Training data shape:',np.shape(train_val_inputs),np.shape(train_val_targets))\n",
    "print('Test data shape:',np.shape(n_test_inputs),np.shape(n_test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening if last layer is fcl\n",
    "#train_val_targets = np.reshape(train_val_targets,(len(train_val_targets),-1))\n",
    "#n_test_targets = np.reshape(n_test_targets,(len(n_test_targets),-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training data shape:',np.shape(train_val_inputs),np.shape(train_val_targets))\n",
    "print('Test data shape:',np.shape(n_test_inputs),np.shape(n_test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution filters\n",
    "f1 = 8\n",
    "f2 = 3\n",
    "#kernel size\n",
    "k1 = 4\n",
    "k2 = 2\n",
    "#stride\n",
    "s1 = 4\n",
    "s2 = 2\n",
    "#padding\n",
    "p1 = 0\n",
    "p2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toy network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential()\n",
    "\n",
    "conv1 = keras.layers.Conv2D(input_shape = (64,64,3),\n",
    "                              filters = f1,\n",
    "                              kernel_size=(k1,k1),\n",
    "                              strides=(s1, s1),\n",
    "                              padding='valid',\n",
    "                              data_format = \"channels_last\",\n",
    "                             activation = 'tanh')\n",
    "conv2 = keras.layers.Conv2D(input_shape = (16,16,3),\n",
    "                              filters = f2,\n",
    "                              kernel_size=(k2,k2),\n",
    "                              strides=(s2, s2),\n",
    "                              padding='same',\n",
    "                              data_format = \"channels_last\",\n",
    "                              activation = 'tanh')\n",
    "conv3 = keras.layers.Conv2D(input_shape = (8,8,3),\n",
    "                              filters = 3,\n",
    "                              kernel_size=(8,8),\n",
    "                              strides=(1, 1),\n",
    "                              padding='same',\n",
    "                              data_format = \"channels_last\",\n",
    "                              activation = 'tanh')\n",
    "upsample1 = keras.layers.UpSampling2D(size=(4, 4), data_format=\"channels_last\",input_shape = (8,8,3))\n",
    "dense1 = keras.layers.Dense(64*64*3,activation='tanh')\n",
    "#architeccture\n",
    "model.add(conv1)\n",
    "model.add(conv2)\n",
    "model.add(conv3)\n",
    "model.add(upsample1)\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(dense1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2=keras.Sequential()\n",
    "\n",
    "init = keras.layers.Input(shape=(64,64,3))\n",
    "ConvDown1  = keras.layers.Conv2D(filters=8,kernel_size=(2,2),strides=(1,1),padding=\"same\")(init)\n",
    "Lr1 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown1)\n",
    "#64\n",
    "ConvDown2  = keras.layers.Conv2D(filters=16,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr1)\n",
    "Lr2 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown2)\n",
    "#32\n",
    "ConvDown3  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr2)\n",
    "Lr3 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown3)\n",
    "#16\n",
    "ConvDown4  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr3)\n",
    "Lr4 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown4)\n",
    "#8\n",
    "ConvDown5  = keras.layers.Conv2D(filters=32,kernel_size=(2,2),strides=(2,2),padding=\"same\")(Lr4)\n",
    "Lr5 = keras.layers.LeakyReLU(alpha=0.0)(ConvDown5)\n",
    "#4\n",
    "\n",
    "UpSamp1 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr5)\n",
    "#8\n",
    "merge1  = keras.layers.concatenate([ConvDown4,UpSamp1],axis=-1)#(UpSamp1)\n",
    "Conv1   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge1)\n",
    "Lr6 = keras.layers.LeakyReLU(alpha=0.0)(Conv1)\n",
    "#8\n",
    "UpSamp2 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr6)\n",
    "#16\n",
    "merge2  = keras.layers.concatenate([ConvDown3,UpSamp2],axis=-1)#(UpSamp2)\n",
    "Conv2   = keras.layers.Conv2D(filters=32,kernel_size=(4,4),strides=(1,1),padding=\"same\")(merge2)\n",
    "Lr7  = keras.layers.LeakyReLU(alpha=0.0)(Conv2)\n",
    "#16\n",
    "UpSamp3 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr7)\n",
    "\n",
    "#32\n",
    "Conv3   = keras.layers.Conv2D(filters=16,kernel_size=(4,4),strides=(1,1),padding=\"same\")(UpSamp3)\n",
    "Lr8  = keras.layers.LeakyReLU(alpha=0.0)(Conv3)\n",
    "\n",
    "UpSamp4 = keras.layers.UpSampling2D(size=(2, 2), data_format=\"channels_last\")(Lr8)\n",
    "#64\n",
    "Conv4   = keras.layers.Conv2D(filters=8,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'relu')(UpSamp4)\n",
    "\n",
    "Conv5   = keras.layers.Conv2D(filters=3,kernel_size=(4,4),strides=(1,1),padding=\"same\",activation = 'elu')(Conv4)\n",
    "\n",
    "model2 = keras.models.Model(inputs=init, outputs=Conv5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "model2.compile(optimizer=tf.train.AdamOptimizer(learning_rate = 0.0001),loss='mean_squared_error', metrics=['accuracy',relative_error_tensor]) \n",
    "model2.fit(train_val_inputs,\n",
    "          train_val_targets,\n",
    "          batch_size = 50,\n",
    "          epochs=50,\n",
    "          validation_split = 0.1,\n",
    "          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss and network info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model2.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trainingcurves(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['relative_error_tensor'],)\n",
    "plt.plot(hist.history['val_relative_error_tensor'])\n",
    "plt.legend(['training', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "predictions = model2.predict(n_test_inputs, batch_size=1)\n",
    "truth     = n_test_targets\n",
    "\n",
    "predictions = np.reshape(predictions, (len(n_test_inputs),64,64,3))\n",
    "truth       = np.reshape(truth, (len(n_test_targets),64,64,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_distribution(truth,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = arg_getter(truth,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotter(predictions,truth,index = args[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_img(reference,output):\n",
    "    mean_ref = reference.mean()\n",
    "    mean_output = output.mean()\n",
    "    rel_err = []\n",
    "    #[rel_err.append(relative_error(mean_ref[:,:,ch], mean_output[:,:,ch])) for ch in range(0,3)]\n",
    "    #ref_mean_truth = np.mean(np.abs(mean_ref))\n",
    "    #ref_mean_pred = np.mean(np.abs(mean_output))\n",
    "    return mean_ref, mean_output#, rel_err, ref_mean_truth, ref_mean_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = denormalize_data(predictions, truth, n_vxmax,n_vymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ref, mean_output = get_mean_img(test_inputs.transpose(0,2,3,1),test_targets.transpose(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.686136044049398"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227.15565280700702"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_targets - test_targets[:,0,:,:].mean(axis = 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(rel_err).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_inputs.transpose(0,2,3,1)[0,:,:,2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
